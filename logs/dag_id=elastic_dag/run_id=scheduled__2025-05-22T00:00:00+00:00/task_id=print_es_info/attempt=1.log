[2025-05-23T04:00:47.348+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: elastic_dag.print_es_info scheduled__2025-05-22T00:00:00+00:00 [queued]>
[2025-05-23T04:00:47.353+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: elastic_dag.print_es_info scheduled__2025-05-22T00:00:00+00:00 [queued]>
[2025-05-23T04:00:47.353+0000] {taskinstance.py:1279} INFO - 
--------------------------------------------------------------------------------
[2025-05-23T04:00:47.353+0000] {taskinstance.py:1280} INFO - Starting attempt 1 of 1
[2025-05-23T04:00:47.353+0000] {taskinstance.py:1281} INFO - 
--------------------------------------------------------------------------------
[2025-05-23T04:00:47.360+0000] {taskinstance.py:1300} INFO - Executing <Task(PythonOperator): print_es_info> on 2025-05-22 00:00:00+00:00
[2025-05-23T04:00:47.364+0000] {standard_task_runner.py:55} INFO - Started process 664 to run task
[2025-05-23T04:00:47.366+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'elastic_dag', 'print_es_info', 'scheduled__2025-05-22T00:00:00+00:00', '--job-id', '489', '--raw', '--subdir', 'DAGS_FOLDER/elastic_dag.py', '--cfg-path', '/tmp/tmp0sc8zmyh']
[2025-05-23T04:00:47.367+0000] {standard_task_runner.py:83} INFO - Job 489: Subtask print_es_info
[2025-05-23T04:00:47.397+0000] {task_command.py:388} INFO - Running <TaskInstance: elastic_dag.print_es_info scheduled__2025-05-22T00:00:00+00:00 [running]> on host 74c05f868d26
[2025-05-23T04:00:47.430+0000] {taskinstance.py:1509} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=elastic_dag
AIRFLOW_CTX_TASK_ID=print_es_info
AIRFLOW_CTX_EXECUTION_DATE=2025-05-22T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-05-22T00:00:00+00:00
[2025-05-23T04:00:47.434+0000] {base.py:73} INFO - Using connection ID 'elastic_default' for task execution.
[2025-05-23T04:00:47.434+0000] {taskinstance.py:1768} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/elastic_dag.py", line 8, in _print_es_info
    hook = ElasticHook()
  File "/opt/airflow/plugins/hooks/elastic/elastic_hook.py", line 15, in __init__
    hosts = conn.host.splt(',')
AttributeError: 'str' object has no attribute 'splt'
[2025-05-23T04:00:47.438+0000] {taskinstance.py:1323} INFO - Marking task as FAILED. dag_id=elastic_dag, task_id=print_es_info, execution_date=20250522T000000, start_date=20250523T040047, end_date=20250523T040047
[2025-05-23T04:00:47.444+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 489 for task print_es_info ('str' object has no attribute 'splt'; 664)
[2025-05-23T04:00:47.465+0000] {local_task_job.py:208} INFO - Task exited with return code 1
[2025-05-23T04:00:47.473+0000] {taskinstance.py:2578} INFO - 0 downstream tasks scheduled from follow-on schedule check
