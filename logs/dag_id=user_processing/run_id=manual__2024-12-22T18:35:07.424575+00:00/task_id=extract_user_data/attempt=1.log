[2024-12-22T18:35:11.353+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: user_processing.extract_user_data manual__2024-12-22T18:35:07.424575+00:00 [queued]>
[2024-12-22T18:35:11.357+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: user_processing.extract_user_data manual__2024-12-22T18:35:07.424575+00:00 [queued]>
[2024-12-22T18:35:11.357+0000] {taskinstance.py:1279} INFO - 
--------------------------------------------------------------------------------
[2024-12-22T18:35:11.357+0000] {taskinstance.py:1280} INFO - Starting attempt 1 of 1
[2024-12-22T18:35:11.357+0000] {taskinstance.py:1281} INFO - 
--------------------------------------------------------------------------------
[2024-12-22T18:35:11.362+0000] {taskinstance.py:1300} INFO - Executing <Task(SimpleHttpOperator): extract_user_data> on 2024-12-22 18:35:07.424575+00:00
[2024-12-22T18:35:11.364+0000] {standard_task_runner.py:55} INFO - Started process 79550 to run task
[2024-12-22T18:35:11.366+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'user_processing', 'extract_user_data', 'manual__2024-12-22T18:35:07.424575+00:00', '--job-id', '173', '--raw', '--subdir', 'DAGS_FOLDER/user_processing.py', '--cfg-path', '/tmp/tmpxb3cg4la']
[2024-12-22T18:35:11.366+0000] {standard_task_runner.py:83} INFO - Job 173: Subtask extract_user_data
[2024-12-22T18:35:11.387+0000] {task_command.py:388} INFO - Running <TaskInstance: user_processing.extract_user_data manual__2024-12-22T18:35:07.424575+00:00 [running]> on host 44e036a430cc
[2024-12-22T18:35:11.411+0000] {taskinstance.py:1509} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=user_processing
AIRFLOW_CTX_TASK_ID=extract_user_data
AIRFLOW_CTX_EXECUTION_DATE=2024-12-22T18:35:07.424575+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2024-12-22T18:35:07.424575+00:00
[2024-12-22T18:35:11.412+0000] {http.py:123} INFO - Calling HTTP method
[2024-12-22T18:35:11.415+0000] {base.py:73} INFO - Using connection ID 'user_api' for task execution.
[2024-12-22T18:35:11.473+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/urllib3/connectionpool.py:1052: InsecureRequestWarning: Unverified HTTPS request is being made to host 'randomuser.me'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings
  InsecureRequestWarning,

[2024-12-22T18:35:11.693+0000] {http.py:127} INFO - {"results":[{"gender":"female","name":{"title":"Ms","first":"Sneha","last":"Thampy"},"location":{"street":{"number":1561,"name":"Swargate"},"city":"Unnao","state":"Puducherry","country":"India","postcode":74047,"coordinates":{"latitude":"9.6812","longitude":"94.3660"},"timezone":{"offset":"-7:00","description":"Mountain Time (US & Canada)"}},"email":"sneha.thampy@example.com","login":{"uuid":"dff32efc-bfb0-4680-b798-d9a9b66e5b6e","username":"orangesnake652","password":"moonbeam","salt":"8UdyHcBD","md5":"4406331f944c6e74b9a184c29bc82d48","sha1":"9319622800a1f55bf40d5f32495a4562380e2746","sha256":"3331239dd4292186d00a88a6e20e661989be82df5a682e0b7cd4684525cdcdca"},"dob":{"date":"1981-06-04T04:03:33.776Z","age":43},"registered":{"date":"2013-07-31T04:27:45.766Z","age":11},"phone":"8483649491","cell":"8455987929","id":{"name":"UIDAI","value":"941724177541"},"picture":{"large":"https://randomuser.me/api/portraits/women/71.jpg","medium":"https://randomuser.me/api/portraits/med/women/71.jpg","thumbnail":"https://randomuser.me/api/portraits/thumb/women/71.jpg"},"nat":"IN"}],"info":{"seed":"df0b777559c97f55","results":1,"page":1,"version":"1.4"}}
[2024-12-22T18:35:11.818+0000] {taskinstance.py:1323} INFO - Marking task as SUCCESS. dag_id=user_processing, task_id=extract_user_data, execution_date=20241222T183507, start_date=20241222T183511, end_date=20241222T183511
[2024-12-22T18:35:11.848+0000] {local_task_job.py:208} INFO - Task exited with return code 0
[2024-12-22T18:35:11.860+0000] {taskinstance.py:2578} INFO - 1 downstream tasks scheduled from follow-on schedule check
