[2024-12-22T18:38:51.307+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: user_processing.extract_user_data manual__2024-12-22T18:38:48.542110+00:00 [queued]>
[2024-12-22T18:38:51.311+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: user_processing.extract_user_data manual__2024-12-22T18:38:48.542110+00:00 [queued]>
[2024-12-22T18:38:51.311+0000] {taskinstance.py:1279} INFO - 
--------------------------------------------------------------------------------
[2024-12-22T18:38:51.311+0000] {taskinstance.py:1280} INFO - Starting attempt 1 of 1
[2024-12-22T18:38:51.311+0000] {taskinstance.py:1281} INFO - 
--------------------------------------------------------------------------------
[2024-12-22T18:38:51.316+0000] {taskinstance.py:1300} INFO - Executing <Task(SimpleHttpOperator): extract_user_data> on 2024-12-22 18:38:48.542110+00:00
[2024-12-22T18:38:51.318+0000] {standard_task_runner.py:55} INFO - Started process 79885 to run task
[2024-12-22T18:38:51.319+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'user_processing', 'extract_user_data', 'manual__2024-12-22T18:38:48.542110+00:00', '--job-id', '178', '--raw', '--subdir', 'DAGS_FOLDER/user_processing.py', '--cfg-path', '/tmp/tmp5ia6_6fv']
[2024-12-22T18:38:51.320+0000] {standard_task_runner.py:83} INFO - Job 178: Subtask extract_user_data
[2024-12-22T18:38:51.341+0000] {task_command.py:388} INFO - Running <TaskInstance: user_processing.extract_user_data manual__2024-12-22T18:38:48.542110+00:00 [running]> on host 44e036a430cc
[2024-12-22T18:38:51.365+0000] {taskinstance.py:1509} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=user_processing
AIRFLOW_CTX_TASK_ID=extract_user_data
AIRFLOW_CTX_EXECUTION_DATE=2024-12-22T18:38:48.542110+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2024-12-22T18:38:48.542110+00:00
[2024-12-22T18:38:51.366+0000] {http.py:123} INFO - Calling HTTP method
[2024-12-22T18:38:51.369+0000] {base.py:73} INFO - Using connection ID 'user_api' for task execution.
[2024-12-22T18:38:51.421+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/urllib3/connectionpool.py:1052: InsecureRequestWarning: Unverified HTTPS request is being made to host 'randomuser.me'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings
  InsecureRequestWarning,

[2024-12-22T18:38:51.518+0000] {http.py:127} INFO - {"results":[{"gender":"female","name":{"title":"Miss","first":"Deborah","last":"Peukert"},"location":{"street":{"number":8415,"name":"Waldstra√üe"},"city":"Bamberg","state":"Saarland","country":"Germany","postcode":16634,"coordinates":{"latitude":"-50.6542","longitude":"34.2617"},"timezone":{"offset":"+8:00","description":"Beijing, Perth, Singapore, Hong Kong"}},"email":"deborah.peukert@example.com","login":{"uuid":"3a2ddf1b-1fb5-439f-8c3c-20f4403f1b40","username":"silverdog102","password":"button","salt":"7QtoM0VY","md5":"fe562feb18eec60473f207f004115f17","sha1":"473f3306b16be9732d822933d1fb7c8a784022ac","sha256":"82d573967c6e97a1f3e3639a0da5cffa8b4ddb0be275be4b923cf0ee28ce809b"},"dob":{"date":"2000-10-23T10:53:14.870Z","age":24},"registered":{"date":"2008-06-03T09:53:47.095Z","age":16},"phone":"0029-0730113","cell":"0175-0512739","id":{"name":"SVNR","value":"45 2310100 P 527"},"picture":{"large":"https://randomuser.me/api/portraits/women/28.jpg","medium":"https://randomuser.me/api/portraits/med/women/28.jpg","thumbnail":"https://randomuser.me/api/portraits/thumb/women/28.jpg"},"nat":"DE"}],"info":{"seed":"6d20bdd68c149bce","results":1,"page":1,"version":"1.4"}}
[2024-12-22T18:38:51.673+0000] {taskinstance.py:1323} INFO - Marking task as SUCCESS. dag_id=user_processing, task_id=extract_user_data, execution_date=20241222T183848, start_date=20241222T183851, end_date=20241222T183851
[2024-12-22T18:38:51.707+0000] {local_task_job.py:208} INFO - Task exited with return code 0
[2024-12-22T18:38:51.720+0000] {taskinstance.py:2578} INFO - 1 downstream tasks scheduled from follow-on schedule check
