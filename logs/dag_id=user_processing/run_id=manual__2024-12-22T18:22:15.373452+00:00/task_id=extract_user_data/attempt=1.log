[2024-12-22T18:22:18.725+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: user_processing.extract_user_data manual__2024-12-22T18:22:15.373452+00:00 [queued]>
[2024-12-22T18:22:18.728+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: user_processing.extract_user_data manual__2024-12-22T18:22:15.373452+00:00 [queued]>
[2024-12-22T18:22:18.728+0000] {taskinstance.py:1279} INFO - 
--------------------------------------------------------------------------------
[2024-12-22T18:22:18.728+0000] {taskinstance.py:1280} INFO - Starting attempt 1 of 1
[2024-12-22T18:22:18.729+0000] {taskinstance.py:1281} INFO - 
--------------------------------------------------------------------------------
[2024-12-22T18:22:18.733+0000] {taskinstance.py:1300} INFO - Executing <Task(SimpleHttpOperator): extract_user_data> on 2024-12-22 18:22:15.373452+00:00
[2024-12-22T18:22:18.735+0000] {standard_task_runner.py:55} INFO - Started process 78327 to run task
[2024-12-22T18:22:18.737+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'user_processing', 'extract_user_data', 'manual__2024-12-22T18:22:15.373452+00:00', '--job-id', '143', '--raw', '--subdir', 'DAGS_FOLDER/user_processing.py', '--cfg-path', '/tmp/tmp7ft4kw7r']
[2024-12-22T18:22:18.737+0000] {standard_task_runner.py:83} INFO - Job 143: Subtask extract_user_data
[2024-12-22T18:22:18.759+0000] {task_command.py:388} INFO - Running <TaskInstance: user_processing.extract_user_data manual__2024-12-22T18:22:15.373452+00:00 [running]> on host 44e036a430cc
[2024-12-22T18:22:18.782+0000] {taskinstance.py:1509} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=user_processing
AIRFLOW_CTX_TASK_ID=extract_user_data
AIRFLOW_CTX_EXECUTION_DATE=2024-12-22T18:22:15.373452+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2024-12-22T18:22:15.373452+00:00
[2024-12-22T18:22:18.783+0000] {http.py:123} INFO - Calling HTTP method
[2024-12-22T18:22:18.786+0000] {base.py:73} INFO - Using connection ID 'user_api' for task execution.
[2024-12-22T18:22:18.839+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/urllib3/connectionpool.py:1052: InsecureRequestWarning: Unverified HTTPS request is being made to host 'randomuser.me'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings
  InsecureRequestWarning,

[2024-12-22T18:22:18.912+0000] {http.py:127} INFO - {"results":[{"gender":"male","name":{"title":"Mr","first":"Jeffrey","last":"Simmons"},"location":{"street":{"number":5601,"name":"Mockingbird Hill"},"city":"Bundaberg","state":"South Australia","country":"Australia","postcode":5168,"coordinates":{"latitude":"-85.3800","longitude":"-27.4522"},"timezone":{"offset":"+5:30","description":"Bombay, Calcutta, Madras, New Delhi"}},"email":"jeffrey.simmons@example.com","login":{"uuid":"7db88385-90e5-4810-b3ea-d89e87c2f83d","username":"whitemouse878","password":"cleopatr","salt":"Ja6wHhdS","md5":"ed9418dc04cc05800d9862d05bd9d291","sha1":"17dc8830978d3aa07962edf7e03c90fc41b7c6ef","sha256":"17fe135cfe2ae85fb136a7ca11c071df287da68720e3e94cc8ab64abc9e9da54"},"dob":{"date":"1973-12-25T07:27:50.344Z","age":50},"registered":{"date":"2014-10-23T13:58:22.569Z","age":10},"phone":"05-4719-5288","cell":"0482-121-853","id":{"name":"TFN","value":"124590294"},"picture":{"large":"https://randomuser.me/api/portraits/men/91.jpg","medium":"https://randomuser.me/api/portraits/med/men/91.jpg","thumbnail":"https://randomuser.me/api/portraits/thumb/men/91.jpg"},"nat":"AU"}],"info":{"seed":"ec885d1ac86ff488","results":1,"page":1,"version":"1.4"}}
[2024-12-22T18:22:19.075+0000] {taskinstance.py:1323} INFO - Marking task as SUCCESS. dag_id=user_processing, task_id=extract_user_data, execution_date=20241222T182215, start_date=20241222T182218, end_date=20241222T182219
[2024-12-22T18:22:19.097+0000] {local_task_job.py:208} INFO - Task exited with return code 0
[2024-12-22T18:22:19.110+0000] {taskinstance.py:2578} INFO - 1 downstream tasks scheduled from follow-on schedule check
